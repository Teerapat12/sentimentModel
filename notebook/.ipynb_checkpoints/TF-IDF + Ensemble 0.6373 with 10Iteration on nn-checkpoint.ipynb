{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/facebook_comment_cleaned.tsv\",sep='\\t',encoding='utf-8')\n",
    "df['token_arr'] = df['token'].apply(lambda x:eval(x))\n",
    "\n",
    "def giveClass(score):\n",
    "    if(score==-32 ):\n",
    "        return -32\n",
    "    if(score==0):return 0\n",
    "    if(score>0):return 1\n",
    "    if(score<0):return -1\n",
    "df['class'] = df['score'].apply(giveClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()\n",
    "scored = df[df['scoredAmt']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments = [i for i in scored['token_arr'].values]\n",
    "vocabs = Counter([word for comment in comments for word in comment])\n",
    "comments = [\" \".join(i) for i in scored['token_arr'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the tf-idf matrix...\n",
      "\n",
      "tf-idf features created\n",
      "CPU times: user 648 ms, sys: 0 ns, total: 648 ms\n",
      "Wall time: 647 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Creating tf-idf\n",
    "print(\"Creating the tf-idf matrix...\\n\")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = [\" \"],   \\\n",
    "                             max_features = 15000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "tfidf_train_features = tfidf_vectorizer.fit_transform(comments)\n",
    "print(\"tf-idf features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 288 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = tfidf_train_features\n",
    "y = scored['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 ms, sys: 0 ns, total: 8 ms\n",
      "Wall time: 8.95 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train,X_test , y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 210 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = AdaBoostClassifier(random_state=1)\n",
    "clf2 =  RandomForestClassifier(n_estimators = 50,random_state=1,criterion='entropy')\n",
    "clf3 = MLPClassifier(hidden_layer_sizes =(500,250),random_state = 1,verbose =True)\n",
    "clf4 = MLPClassifier()\n",
    "clf5 = LogisticRegression()\n",
    "clf6 = KNeighborsClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model: Ada\n",
      "Finished training in 4 seconds\n",
      "Accuracy: 59.85%\n",
      "[[529  67  18  21]\n",
      " [ 95 587  39  41]\n",
      " [153  99  53  69]\n",
      " [108  92  62 119]]\n",
      "Start training model: RandomForest\n",
      "Finished training in 3 seconds\n",
      "Accuracy: 61.71%\n",
      "[[508  81  23  23]\n",
      " [ 80 624  36  22]\n",
      " [ 76 134  87  77]\n",
      " [ 75 122  75 109]]\n",
      "Start training model: MultinomialNB\n",
      "Finished training in 0 seconds\n",
      "Accuracy: 54.04%\n",
      "[[304 314   1  16]\n",
      " [  3 757   0   2]\n",
      " [ 19 301   9  45]\n",
      " [ 31 252   5  93]]\n",
      "Start training model: Neural Network\n",
      "Finished training in 267 seconds\n",
      "Accuracy: 60.69%\n",
      "[[464  69  35  67]\n",
      " [ 69 550  81  62]\n",
      " [ 74  97 110  93]\n",
      " [ 58  62  79 182]]\n",
      "Start training model: Logistic Regression\n",
      "Finished training in 0 seconds\n",
      "Accuracy: 65.8%\n",
      "[[533  72  11  19]\n",
      " [ 78 652  13  19]\n",
      " [108 110  63  93]\n",
      " [ 90  79  44 168]]\n",
      "Start training model: KNeighbors\n",
      "Finished training in 0 seconds\n",
      "Accuracy: 34.43%\n",
      "[[604  11   8  12]\n",
      " [694  60   4   4]\n",
      " [308  17  29  20]\n",
      " [308   6  19  48]]\n",
      "CPU times: user 4min 35s, sys: 3.61 s, total: 4min 38s\n",
      "Wall time: 4min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clfs = [clf1,clf2,clf3,clf4,clf5,clf6]\n",
    "names = ['Ada','RandomForest','MultinomialNB','Neural Network','Logistic Regression','KNeighbors']\n",
    "for i,clf in enumerate(clfs):\n",
    "    start = time.time()\n",
    "    print(\"Start training model: %s\"%names[i])\n",
    "    clf.fit(X_train,y_train)\n",
    "    end = time.time()\n",
    "    print(\"Finished training in {} seconds\".format(round(end - start),2))\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Accuracy: {}%\".format(round((acc*100),2)))\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.15264062\n",
      "Iteration 2, loss = 0.74704961\n",
      "Iteration 3, loss = 0.53885464\n",
      "Iteration 4, loss = 0.39832123\n",
      "Iteration 5, loss = 0.29024543\n",
      "Iteration 6, loss = 0.23208796\n",
      "Iteration 7, loss = 0.17231346\n",
      "Iteration 8, loss = 0.14794951\n",
      "Iteration 9, loss = 0.10948597\n",
      "Iteration 10, loss = 0.09378809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/u5722780406/miniconda3/envs/tf/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66124535316\n",
      "[[545  62  12  16]\n",
      " [ 69 663  17  13]\n",
      " [100 136  57  81]\n",
      " [ 91  88  44 158]]\n",
      "CPU times: user 3min 39s, sys: 20min 53s, total: 24min 33s\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf1 = RandomForestClassifier(n_estimators = 70,random_state=1,criterion='entropy')\n",
    "clf2 = LogisticRegression()\n",
    "clf3 = MLPClassifier(hidden_layer_sizes =(400,250,150),random_state = 1,verbose =True,max_iter=10)\n",
    "\n",
    "#We will choose RandomForest, LogisticRegression, and neural network to form ensemble model\n",
    "eclf1 = VotingClassifier(estimators=[('rf', clf1), ('lr', clf2), ('mlp', clf3)], voting='hard')\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "y_pred = eclf1.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(acc)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eclf1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b9479954374c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Try with cross validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meclf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'eclf1' is not defined"
     ]
    }
   ],
   "source": [
    "#Try with cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(eclf1, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model: Random Forest\n",
      "Finished training in 14 seconds\n",
      "Accuracy: 65.2%\n",
      "[[507  85  21  22]\n",
      " [ 47 687  18  10]\n",
      " [ 65 148  66  95]\n",
      " [ 61 118  59 143]]\n"
     ]
    }
   ],
   "source": [
    "#Let's tune random forest first\n",
    "n_estimators = 50\n",
    "start = time.time()\n",
    "clf2 = RandomForestClassifier(n_estimators = n_estimators,random_state=1,criterion='entropy')\n",
    "print(\"Start training model: Random Forest\")\n",
    "clf2.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "print(\"Finished training in {} seconds\".format(round(end - start),2))\n",
    "y_pred = clf2.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy: {}%\".format(round((acc*100),2)))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training model: Neural Network\n",
      "Iteration 1, loss = 1.06975231\n",
      "Iteration 2, loss = 0.67920089\n",
      "Iteration 3, loss = 0.45709190\n",
      "Iteration 4, loss = 0.31590554\n",
      "Iteration 5, loss = 0.22215293\n",
      "Iteration 6, loss = 0.16337140\n",
      "Iteration 7, loss = 0.14133826\n",
      "Iteration 8, loss = 0.11043541\n",
      "Iteration 9, loss = 0.09355110\n",
      "Iteration 10, loss = 0.07802286\n",
      "Iteration 11, loss = 0.06853948\n",
      "Iteration 12, loss = 0.06668588\n",
      "Iteration 13, loss = 0.06750333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Let's tune random forest first\n",
    "n_estimators = 50\n",
    "start = time.time()\n",
    "clf4 = MLPClassifier(hidden_layer_sizes =(1000,500),random_state = 1,verbose =True)\n",
    "print(\"Start training model: Neural Network\")\n",
    "clf4.fit(X_train,y_train)\n",
    "end = time.time()\n",
    "print(\"Finished training in {} seconds\".format(round(end - start),2))\n",
    "y_pred = clf4.predict(X_test)\n",
    "acc = accuracy_score(clf4.predict(X_train), y_train)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy(train): {}%\".format(round((acc*100),2)))\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {}%\".format(round((acc*100),2)))\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
